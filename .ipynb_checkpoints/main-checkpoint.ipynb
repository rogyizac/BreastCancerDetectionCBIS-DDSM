{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e00609f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from dataset import get_train_valid, get_dataloaders\n",
    "from utils import plot_training, n_p, get_count\n",
    "\n",
    "from vgg16 import VGG16\n",
    "from train import train_model, get_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a59905e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training set and the metadata file\n",
    "df_train_set = pd.read_csv(r'calc_case_description_train_set.csv')\n",
    "df_metadata = pd.read_csv(r'/data0/NIH-CXR14/images/CBIS_DDSM/Calc-Training_full_mammogram_images_1-doiJNLP-PrQ05L6k (1)/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "873907a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Files preprocess\n",
    "\n",
    "# pick file name and set labels\n",
    "df_train_set['image_file_name'] = df_train_set['image file path'].str.split('/').apply(lambda x : x[0])\n",
    "df_train_set.loc[df_train_set['pathology'].str.startswith('BENIGN'), 'pathology'] = 0\n",
    "df_train_set.loc[df_train_set['pathology'] == 'MALIGNANT', 'pathology'] = 1\n",
    "\n",
    "# train dataset does not have right file paths, take it from metadata\n",
    "df_metadata = df_metadata[['Subject ID', 'File Location']]\n",
    "df_metadata['File Location'] = df_metadata['File Location'].str[2:]\n",
    "local_path = r'/data0/NIH-CXR14/images/CBIS_DDSM/Calc-Training_full_mammogram_images_1-doiJNLP-PrQ05L6k (1)'\n",
    "df_metadata['File Location'] = local_path + '/' + df_metadata['File Location'] + '/' + '1-1.dcm'\n",
    "df_train_set = df_train_set.merge(df_metadata.rename(columns = {'Subject ID' : 'image_file_name'}), on = ['image_file_name'], how = 'left')\n",
    "\n",
    "# drop rows where file location is not available\n",
    "df_train_set = df_train_set.dropna(subset = ['File Location'])\n",
    "# subset required columns\n",
    "df_train_set = df_train_set[['patient_id', 'image_file_name', 'File Location', 'pathology']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca216cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataloaders\n",
    "\n",
    "# train validation split\n",
    "train_data, valid_data = get_train_valid(df_train_set)\n",
    "\n",
    "# get dataloaders\n",
    "dataloaders = get_dataloaders(train_data, valid_data, batch_size = 1)\n",
    "dataset_sizes = {'train': len(train_data), 'valid' : len(valid_data)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "847ede3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tai: {'train': 418, 'valid': 126}\n",
      "tni: {'train': 819, 'valid': 183} \n",
      "\n",
      "Wt0 train: tensor([0.3379], device='cuda:0')\n",
      "Wt0 valid: tensor([0.4078], device='cuda:0')\n",
      "Wt1 train: tensor([0.6621], device='cuda:0')\n",
      "Wt1 valid: tensor([0.5922], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# prepare & run model\n",
    "data_cat = ['train', 'valid']\n",
    "# tai = total abnormal images, tni = total normal images\n",
    "tai = {'train': get_count(train_data, 1), 'valid': get_count(valid_data, 1)}\n",
    "tni = {'train': get_count(train_data, 0), 'valid': get_count(valid_data, 0)}\n",
    "Wt1 = {x: n_p(tni[x] / (tni[x] + tai[x])) for x in data_cat}\n",
    "Wt0 = {x: n_p(tai[x] / (tni[x] + tai[x])) for x in data_cat}\n",
    "\n",
    "print('tai:', tai)\n",
    "print('tni:', tni, '\\n')\n",
    "print('Wt0 train:', Wt0['train'])\n",
    "print('Wt0 valid:', Wt0['valid'])\n",
    "print('Wt1 train:', Wt1['train'])\n",
    "print('Wt1 valid:', Wt1['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6a07f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-risaac/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jupyter-risaac/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "class Loss(torch.nn.modules.Module):\n",
    "    def __init__(self, Wt1, Wt0):\n",
    "        super(Loss, self).__init__()\n",
    "        self.Wt1 = Wt1\n",
    "        self.Wt0 = Wt0\n",
    "\n",
    "    def forward(self, inputs, targets, phase):\n",
    "#         targets = targets.squeeze(dim=1)\n",
    "#         print(inputs, targets)\n",
    "        loss = torch.nn.functional.binary_cross_entropy(inputs, targets,\n",
    "                                                        weight=(self.Wt1[phase] * targets + self.Wt0[phase] * (1 - targets)))\n",
    "        return loss\n",
    "    \n",
    "model = VGG16(num_classes=1)\n",
    "model = model.cuda()\n",
    "\n",
    "criterion = Loss(Wt1, Wt0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f6fa62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 1237\n",
      "Valid batches: 309 \n",
      "\n",
      "Epoch 1/10\n",
      "----------\n",
      "tensor([[0.5204]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.4592]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.3497]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[1.]], device='cuda:0')\n",
      "tensor([[0.3427]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[1.]], device='cuda:0')\n",
      "tensor([[0.4249]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[1.]], device='cuda:0')\n",
      "tensor([[0.4634]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[1.]], device='cuda:0')\n",
      "tensor([[0.5170]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.5148]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.5245]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.5341]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.4880]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[1.]], device='cuda:0')\n",
      "tensor([[0.5190]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.4954]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.4803]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.4546]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.4593]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[1.]], device='cuda:0')\n",
      "tensor([[0.4633]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[1.]], device='cuda:0')\n",
      "tensor([[0.4259]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.4326]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.4193]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[1.]], device='cuda:0')\n",
      "tensor([[0.4759]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[1.]], device='cuda:0')\n",
      "tensor([[0.4264]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.4814]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[1.]], device='cuda:0')\n",
      "tensor([[0.4671]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.4647]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.4601]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[1.]], device='cuda:0')\n",
      "tensor([[0.5363]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[1.]], device='cuda:0')\n",
      "tensor([[0.5053]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[1.]], device='cuda:0')\n",
      "tensor([[0.5419]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.5373]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.5052]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[1.]], device='cuda:0')\n",
      "tensor([[0.5371]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.5858]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[1.]], device='cuda:0')\n",
      "tensor([[0.5580]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.6490]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.5277]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[1.]], device='cuda:0')\n",
      "tensor([[0.6647]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[1.]], device='cuda:0')\n",
      "tensor([[0.6875]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.5491]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.5364]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.6356]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.4834]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.5195]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[1.]], device='cuda:0')\n",
      "tensor([[0.4786]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.4594]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.4638]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[1.]], device='cuda:0')\n",
      "tensor([[0.5224]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.4983]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n",
      "tensor([[0.4702]], device='cuda:0', grad_fn=<SigmoidBackward0>) tensor([[0.]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# #### Train model\n",
    "model = train_model(model, criterion, optimizer, dataloaders, scheduler, dataset_sizes, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d1cf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5427f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics(model, criterion, dataloaders, dataset_sizes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
