{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e00609f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from dataset import get_train_valid, get_dataloaders\n",
    "from utils import plot_training, n_p, get_count\n",
    "\n",
    "from vgg16 import VGG16\n",
    "from train import train_model, get_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a59905e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training set and the metadata file\n",
    "df_train_set = pd.read_csv(r'calc_case_description_train_set.csv')\n",
    "df_metadata = pd.read_csv(r'/data0/NIH-CXR14/images/CBIS_DDSM/Calc-Training_full_mammogram_images_1-doiJNLP-PrQ05L6k (1)/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "873907a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Files preprocess\n",
    "\n",
    "# pick file name and set labels\n",
    "df_train_set['image_file_name'] = df_train_set['image file path'].str.split('/').apply(lambda x : x[0])\n",
    "df_train_set.loc[df_train_set['pathology'].str.startswith('BENIGN'), 'pathology'] = 0\n",
    "df_train_set.loc[df_train_set['pathology'] == 'MALIGNANT', 'pathology'] = 1\n",
    "\n",
    "# train dataset does not have right file paths, take it from metadata\n",
    "df_metadata = df_metadata[['Subject ID', 'File Location']]\n",
    "df_metadata['File Location'] = df_metadata['File Location'].str[2:]\n",
    "local_path = r'/data0/NIH-CXR14/images/CBIS_DDSM/Calc-Training_full_mammogram_images_1-doiJNLP-PrQ05L6k (1)'\n",
    "df_metadata['File Location'] = local_path + '/' + df_metadata['File Location'] + '/' + '1-1.dcm'\n",
    "df_train_set = df_train_set.merge(df_metadata.rename(columns = {'Subject ID' : 'image_file_name'}), on = ['image_file_name'], how = 'left')\n",
    "\n",
    "# drop rows where file location is not available\n",
    "df_train_set = df_train_set.dropna(subset = ['File Location'])\n",
    "# subset required columns\n",
    "df_train_set = df_train_set[['patient_id', 'image_file_name', 'File Location', 'pathology']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca216cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataloaders\n",
    "\n",
    "# train validation split\n",
    "train_data, valid_data = get_train_valid(df_train_set)\n",
    "\n",
    "# get dataloaders\n",
    "dataloaders = get_dataloaders(train_data, valid_data, batch_size = 10)\n",
    "dataset_sizes = {'train': len(train_data), 'valid' : len(valid_data)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "847ede3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tai: {'train': 443, 'valid': 101}\n",
      "tni: {'train': 794, 'valid': 208} \n",
      "\n",
      "Wt0 train: tensor([0.3581], device='cuda:0')\n",
      "Wt0 valid: tensor([0.3269], device='cuda:0')\n",
      "Wt1 train: tensor([0.6419], device='cuda:0')\n",
      "Wt1 valid: tensor([0.6731], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# prepare & run model\n",
    "data_cat = ['train', 'valid']\n",
    "# tai = total abnormal images, tni = total normal images\n",
    "tai = {'train': get_count(train_data, 1), 'valid': get_count(valid_data, 1)}\n",
    "tni = {'train': get_count(train_data, 0), 'valid': get_count(valid_data, 0)}\n",
    "Wt1 = {x: n_p(tni[x] / (tni[x] + tai[x])) for x in data_cat}\n",
    "Wt0 = {x: n_p(tai[x] / (tni[x] + tai[x])) for x in data_cat}\n",
    "\n",
    "print('tai:', tai)\n",
    "print('tni:', tni, '\\n')\n",
    "print('Wt0 train:', Wt0['train'])\n",
    "print('Wt0 valid:', Wt0['valid'])\n",
    "print('Wt1 train:', Wt1['train'])\n",
    "print('Wt1 valid:', Wt1['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6a07f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-risaac/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jupyter-risaac/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "class Loss(torch.nn.modules.Module):\n",
    "    def __init__(self, Wt1, Wt0):\n",
    "        super(Loss, self).__init__()\n",
    "        self.Wt1 = Wt1\n",
    "        self.Wt0 = Wt0\n",
    "\n",
    "    def forward(self, inputs, targets, phase):\n",
    "#         targets = targets.squeeze(dim=1)\n",
    "#         print(inputs, targets)\n",
    "        loss = torch.nn.functional.binary_cross_entropy(inputs, targets,\n",
    "                                                        weight=(self.Wt1[phase] * targets + self.Wt0[phase] * (1 - targets)))\n",
    "        return loss\n",
    "    \n",
    "model = VGG16(num_classes=1)\n",
    "model = model.cuda()\n",
    "\n",
    "criterion = Loss(Wt1, Wt0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6fa62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 118\n",
      "Valid batches: 37 \n",
      "\n",
      "Epoch 1/15\n",
      "----------\n",
      "train Loss: 0.0305 Acc: 0.6144\n",
      "Confusion Matrix:\n",
      " [[441 296]\n",
      " [159 284]]\n",
      "valid Loss: 0.0247 Acc: 0.7459\n",
      "Confusion Matrix:\n",
      " [[215  50]\n",
      " [ 43  58]]\n",
      "Time elapsed: 4m 30s\n",
      "\n",
      "Epoch 2/15\n",
      "----------\n",
      "train Loss: 0.0294 Acc: 0.6441\n",
      "Confusion Matrix:\n",
      " [[427 310]\n",
      " [110 333]]\n",
      "valid Loss: 0.0234 Acc: 0.5683\n",
      "Confusion Matrix:\n",
      " [[119 146]\n",
      " [ 12  89]]\n",
      "Time elapsed: 8m 59s\n",
      "\n",
      "Epoch 3/15\n",
      "----------\n",
      "train Loss: 0.0258 Acc: 0.7008\n",
      "Confusion Matrix:\n",
      " [[463 274]\n",
      " [ 79 364]]\n",
      "valid Loss: 0.0247 Acc: 0.7842\n",
      "Confusion Matrix:\n",
      " [[215  50]\n",
      " [ 29  72]]\n",
      "Time elapsed: 13m 30s\n",
      "\n",
      "Epoch 4/15\n",
      "----------\n",
      "train Loss: 0.0256 Acc: 0.6992\n",
      "Confusion Matrix:\n",
      " [[460 277]\n",
      " [ 78 365]]\n",
      "valid Loss: 0.0244 Acc: 0.4973\n",
      "Confusion Matrix:\n",
      " [[ 91 174]\n",
      " [ 10  91]]\n",
      "Epoch 00004: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Time elapsed: 18m 5s\n",
      "\n",
      "Epoch 5/15\n",
      "----------\n",
      "train Loss: 0.0227 Acc: 0.7364\n",
      "Confusion Matrix:\n",
      " [[472 265]\n",
      " [ 46 397]]\n",
      "valid Loss: 0.0236 Acc: 0.6557\n",
      "Confusion Matrix:\n",
      " [[154 111]\n",
      " [ 15  86]]\n",
      "Time elapsed: 22m 42s\n",
      "\n",
      "Epoch 6/15\n",
      "----------\n",
      "train Loss: 0.0218 Acc: 0.7424\n",
      "Confusion Matrix:\n",
      " [[478 259]\n",
      " [ 45 398]]\n",
      "valid Loss: 0.0232 Acc: 0.7432\n",
      "Confusion Matrix:\n",
      " [[190  75]\n",
      " [ 19  82]]\n",
      "Time elapsed: 27m 18s\n",
      "\n",
      "Epoch 7/15\n",
      "----------\n",
      "train Loss: 0.0206 Acc: 0.7585\n",
      "Confusion Matrix:\n",
      " [[503 234]\n",
      " [ 51 392]]\n",
      "valid Loss: 0.0246 Acc: 0.7596\n",
      "Confusion Matrix:\n",
      " [[195  70]\n",
      " [ 18  83]]\n",
      "Time elapsed: 31m 54s\n",
      "\n",
      "Epoch 8/15\n",
      "----------\n",
      "7\r"
     ]
    }
   ],
   "source": [
    "# #### Train model\n",
    "model = train_model(model, criterion, optimizer, dataloaders, scheduler, dataset_sizes, num_epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d1cf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d04c0685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation\n",
    "model = VGG16(num_classes=1)\n",
    "model = model.cuda()\n",
    "model.load_state_dict(torch.load(r'models/model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5427f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[175  33]\n",
      " [ 31  70]]\n",
      "valid Loss: 0.2169 Acc: 0.7929\n"
     ]
    }
   ],
   "source": [
    "get_metrics(model, criterion, dataloaders, dataset_sizes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
